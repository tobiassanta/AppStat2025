{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Stratification - beating the $1 / \\sqrt{N}$ law\n",
    "\n",
    "The key idea in stratification is to split the data (or domain for integrals) on which we wish to calculate an expectation into strata (i.e. parts). Then, on each of these strata, we calculate the expectation separately, using whatever method is appropriate for the stratum, and which gives us the lowest variance. These expectations are then combined together to get the final value, which has better precision than the usual $1 / \\sqrt{N}$ law.\n",
    "\n",
    "In other words we can achieve better sampling in needed regions by going away from a one-size-fits-all sampling scheme. One way to think about it is that regions with higher variability might need more samples, while not-so-varying regions could make do with less.\n",
    "\n",
    "Stratification is thus a method for obtaining better estimates by subdividing a sample into more homogeneous strata, and then combining the result from each of these to get the final result. The method especially has its real life application in situations, where sampling is expensive, e.g. poling for elections, sampling customers, and patient data analysis.\n",
    "\n",
    "For more information see P. R. Bevington: page 75-78\n",
    "\n",
    "***\n",
    "\n",
    "### Authors: \n",
    "- Troels C. Petersen (Niels Bohr Institute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters of the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = False         # Determining if plots are saved or not\n",
    "r = np.random\n",
    "r.seed(42)\n",
    "\n",
    "# Define short hand function:\n",
    "Y = lambda x: x/(x**2+1.0);\n",
    "\n",
    "# Set parameters:\n",
    "N = 10000         # Number of points\n",
    "Ns = 10           # Number of strata \n",
    "Ntry = 1000       # Number of points we use for finding the Std. in each strata\n",
    "Nrep = 1000       # Number of times we repeat the stratification experiment\n",
    "\n",
    "xmin =  0\n",
    "xmax = 10\n",
    "step = (xmax - xmin) / Ns\n",
    "\n",
    "Imc = np.zeros(Nrep)    # Results from \"normal\" MC sampling (i.e. unstratified)\n",
    "Is  = np.zeros(Nrep)    # Results from stratified sampling with equal sampling in each strata (better)\n",
    "Is2 = np.zeros(Nrep)    # Results from stratified sampling with sampling according to Std. in strata (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to estimate the integral, then we would use the below (not used in this exercise):\n",
    "intY = lambda x: np.log(x**2 + 1.0)/2.0;\n",
    "\n",
    "# Analytic solution :\n",
    "Ic = intY(xmax)-intY(xmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the distribution and its stratification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,6])\n",
    "\n",
    "## Ploting the original functions h(x)\n",
    "plt.subplot(1,2,1)\n",
    "x = np.linspace(0,10,100)\n",
    "plt.plot(x, Y(x), label=u'$h(x) = x/(x^2+1)$')\n",
    "plt.legend(loc=\"upper right\", fontsize=18)\n",
    "plt.ylim(0.0,None)\n",
    "for j in range(Ns+1):\n",
    "    plt.axvline(xmin + j*step, 0, 1, color='r', alpha=0.2)\n",
    "\n",
    "# Plotting the values obtained from inserting uniformily into h(x)\n",
    "plt.subplot(1,2,2)\n",
    "Utry = np.random.uniform(low=xmin, high=xmax, size=Ntry)      # Ntry random uniform numbers\n",
    "Ytry = Y(Utry)                                                # h(x) value of the above numbers\n",
    "plt.hist(Ytry, bins=50, range=(0.0, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea of stratification:\n",
    "\n",
    "We want to find the mean of $h(x)$ given some (fixed) number of samplings of $x$. We can of course just take a lot of values of $x$ and calculate values of $h(x)$ and then take the mean of these. This is the usual Monte Carlo method that we use.\n",
    "\n",
    "But when $x$ is high, the standard deviation (Std) is not very large in $h(x)$, and so we can get a better estimate from:<br>\n",
    "1. Calculating the mean in each strata (using an equal number of samplings in each) and then combining these means.\n",
    "2. Use a different number of samplings in each strata, proportinal to the Std (since small Std requires small number of samplings).\n",
    "\n",
    "Thus, instead of taking the mean of $N$ samples, we break the interval into $M$ strata and take $n_j$ samples for each strata $j$, such that $N=\\sum_j n_j$.\n",
    "\n",
    "If we defining the mean for each strata as $\\hat{\\mu}_j = \\frac{1}{n_j} \\sum_{x_{ij} \\in f_j} h(x_{ij})$, then we can then define the stratified estimator of the overall expectation based on the above means: $\\hat{\\mu}_s = \\sum_j p_j \\hat{\\mu}_j$, which is an unbiased estimator of $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sigmas = np.zeros(Ns)\n",
    "Umin = 0 \n",
    "Umax = step\n",
    "for strata in np.arange(0, Ns) :\n",
    "    strata_mask = (Utry >= Umin) & (Utry < Umax)     # Select only the values that are in the current strata\n",
    "    sigmas[strata] = np.std(Ytry[strata_mask])\n",
    "    Umin = Umin + step\n",
    "    Umax = Umin + step\n",
    "\n",
    "# From the above, calculate the suggested number of samplings to make in each strata:\n",
    "nums = np.floor(N*sigmas/np.sum(sigmas) + 0.5).astype(int)\n",
    "\n",
    "# Print results:\n",
    "np.set_printoptions(precision=3)\n",
    "print(\"Sigmas: \", sigmas)        # Std. (i.e. proportionel to uncertainty in mean) in each strata\n",
    "print(\"Numbers:\", nums)         # Suggested number of samplings in each strata\n",
    "print(\"Sum:    \", np.sum(nums))     # Sum of suggestions (should roughly match input size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot \"experimental\" process:\n",
    "\n",
    "Distribution of points from one experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in np.arange(0, Nrep):\n",
    "\n",
    "    # First, lets do it with mean MC (standard) method: \n",
    "    U = np.random.uniform(low=xmin, high=xmax, size=N)\n",
    "    Imc[k] = (xmax-xmin) * np.mean(Y(U))\n",
    "\n",
    "    # Next, stratified it in Ns regions with equal (I) and optimal (I2) number in each strata:\n",
    "    Umin = 0 \n",
    "    Umax = step\n",
    "    Ii = 0\n",
    "    I2i = 0\n",
    "    for reg in np.arange(0, Ns) :\n",
    "        x = np.random.uniform(low=Umin, high=Umax, size=N//Ns);\n",
    "        Ii = Ii + (Umax-Umin)*np.mean(Y(x))\n",
    "        x2 = np.random.uniform(low=Umin, high=Umax, size=nums[reg]);\n",
    "        I2i = I2i + (Umax-Umin)*np.mean(Y(x2))\n",
    "        Umin = Umin + step\n",
    "        Umax = Umin + step\n",
    "\n",
    "\n",
    "    Is[k] = Ii\n",
    "    Is2[k] = I2i\n",
    "\n",
    "# Resulting Std of the estimates:\n",
    "print(f\"  Standard MC: {np.std(Imc):6.4f}     Stratified:  Equal N: {np.std(Is):6.4f}   Sigma N: {np.std(Is2):6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of results from repeated \"experiments\":\n",
    "Nbins = 80\n",
    "plt.hist(Imc, bins=Nbins, range=(2.27,2.35), histtype='stepfilled', label=u'Normal MC', alpha=0.5)\n",
    "plt.hist(Is,  bins=Nbins, range=(2.27,2.35), histtype='stepfilled', label=u'Stratified (equal)', alpha=0.4)\n",
    "plt.hist(Is2, bins=Nbins, range=(2.27,2.35), histtype='stepfilled', label=u'Stratified (sigma)', alpha=0.3)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Questions:\n",
    "\n",
    "0. First acquaint yourself with the program, and make sure that you understand what e.g. the parameters `N`, `Ntry`, and `Nrep` refer to!\n",
    "Then, run the program, and take a look at the results. Make sure you understand both the plots and the numbers printed.\n",
    "\n",
    "1. How large is the gain in precision when going from MC to equal sampling strata? And when going on to sigma sampling strata?\n",
    "\n",
    "2. Imagine that you were sampling 100 times from three Gaussian distributions:\n",
    "       $G_1(\\mu=0, \\sigma=1.0)$, $G_2(\\mu=0.5, \\sigma=1.5)$, and $G_1(\\mu=1.0, \\sigma=4.0)$<br>\n",
    "   How would you best sample from this combined (3G) PDF? Repeat the above exercises (using known Stds) and see the effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning points:\n",
    "\n",
    "This is an exercise in stratification, i.e. subdividing a sample into more homogenius subsamples to achieve better sample estimates (e.g. mean).\n",
    "\n",
    "From the exercise you should:\n",
    "1. Know the difference between normal (MC) sampling and stratified sampling, both equal size sampling per strata and proportional to the strata Std.\n",
    "2. Understand why stratified sampling is more efficient, and that the gain depends on the size of the differences between strata.\n",
    "3. Be able to perform stratified sampling, and to design a stratified sampling strategy for a planned (real life) sampling."
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "main_language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
