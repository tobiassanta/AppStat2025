{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChiSquare test/distribution for general fits:\n",
    "\n",
    "This Python program/notebook illustrates the use of ChiSquare as a goodness-of-fit measure, how this distribution comes about, and that it actually works, here with three different examples! The first example is the linear fit, while the two others are more complicated (oscillatory graph fit and exponential fit of a histogram). However, they have one thing in common, namely the number of degrees of freedom!\n",
    "\n",
    "## References:\n",
    "* Barlow: Chapter 6\n",
    "* Cowan: Chapter 2.7, Chapter 7\n",
    "* Bevington: Chapter 6\n",
    "\n",
    "## Author(s), contact(s), and dates:\n",
    "* Author: Troels C. Petersen (NBI)\n",
    "* Email:  petersen@nbi.dk\n",
    "* Date:   10th of November 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import LeastSquares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Make sure you've read the relevant references and that you understand not only what\n",
    "the ChiSquare is, but also that it follows the ChiSquare distribution, and that the\n",
    "probability of obtaining such a ChiSquare or worse can be calculated from it.\n",
    "\n",
    "The program generates a certain number of datasets in three different ways, from\n",
    "which the Chi2 of the fit is recorded.\n",
    "***\n",
    "\n",
    "## Program settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minuit.print_level = 0      # Don't print the fit result (many fits to do!)\n",
    "save_plots = False\n",
    "\n",
    "r = np.random                         # Random generator\n",
    "r.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and fit LINEAR data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nexp = 1000\n",
    "NpointsLin = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = 3.6\n",
    "alpha1 = 0.3\n",
    "sigmay = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_Chi2_Lin = np.zeros(Nexp)\n",
    "array_Prob_Lin = np.zeros(Nexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over number of experiments to generate data and subsequent Chi2 values:\n",
    "for iexp in range( Nexp ) : \n",
    "\n",
    "    # Generate points:\n",
    "    xLin = np.arange(NpointsLin)+1\n",
    "    yLin = alpha0 + alpha1 * xLin + r.normal(0, sigmay, NpointsLin)\n",
    "    syLin = sigmay*np.ones_like(xLin)\n",
    "\n",
    "    def fit_function_Lin(x, alpha0, alpha1):\n",
    "        return alpha0 + alpha1*x\n",
    "    \n",
    "    mfitLin = LeastSquares( xLin, yLin, syLin, fit_function_Lin)\n",
    "    mfitLin = Minuit(mfitLin, alpha0=1, alpha1=1)  \n",
    "    mfitLin.migrad();  # perform the actual fit\n",
    "\n",
    "    Chi2Lin = mfitLin.fval # the chi2 value\n",
    "    NvarLin = 2                      # Number of variables (alpha0 and alpha1)\n",
    "    NdofLin = NpointsLin - NvarLin   # Number of degrees of freedom\n",
    "    ProbLin =  stats.chi2.sf(Chi2Lin, NdofLin) # The chi2 probability given N_DOF degrees of freedom\n",
    "    \n",
    "    array_Chi2_Lin[iexp] = Chi2Lin\n",
    "    array_Prob_Lin[iexp] = ProbLin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to inspect the fits, we plot the last one produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figLin, axLin = plt.subplots(figsize=(16, 8))\n",
    "data_plot = axLin.errorbar(xLin, yLin, syLin, fmt='ro', ecolor='k', elinewidth=1, capsize=2, capthick=1, label=\"Data\")\n",
    "fit_plot = axLin.plot(xLin, fit_function_Lin(xLin, *mfitLin.values[:]), '-r', label=\"Fit\")\n",
    "first_legend = axLin.legend(fontsize=18, loc=\"upper left\");\n",
    "\n",
    "chi2 = mfitLin.fval                           # ChiSquare value\n",
    "Ndof = len(xLin) - mfitLin.nfit               # Number of points - Number of fit parameters\n",
    "Prob = stats.chi2.sf(chi2, Ndof)              # ChiSquare probability given Ndof\n",
    "\n",
    "# Box with \"nice\" fit information (and correct number of significant decimals):\n",
    "fit_info = (\n",
    "    f\"$\\\\chi^2$ / $N_\\\\mathrm{{dof}}$ = {chi2:.1f} / {Ndof}\\n\"\n",
    "    f\"Prob($\\\\chi^2$, $N_\\\\mathrm{{dof}}$) = {Prob:.3f}\\n\")\n",
    "for p, v, e in zip(mfitLin.parameters, mfitLin.values[:], mfitLin.errors[:]) :\n",
    "    Ndecimals = max(0,-np.int32(np.log10(e)-1-np.log10(2)))                                # Number of significant digits\n",
    "    fit_info+=(f\"{p} = ${v:{10}.{Ndecimals}{\"f\"}} \\\\pm {e:{10}.{Ndecimals}{\"f\"}}$\\n\")\n",
    "\n",
    "# Add result of fit on the plot in a separate legend\n",
    "fit_results, = plt.plot([],[],color='none',label=fit_info)\n",
    "second_legend = plt.legend(title=\"Result of fit:\", handles=[fit_results], fontsize=18, title_fontsize = 20, alignment = 'left', handlelength=0, handletextpad=0, loc=\"lower right\");\n",
    "axLin.add_artist(first_legend); # add second legend (with fit info) to the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save_plots) : \n",
    "    figLin.savefig(\"Chi2Dist_LinearFit.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and fit OSCILLATING data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NpointsOsc = 19\n",
    "mean  = 1.6\n",
    "amp   = 3.3\n",
    "omega = 0.7\n",
    "phase = 0.3\n",
    "sigmay = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Again we record the resulting Chi2 values and probabilities:\n",
    "array_Chi2_Osc = np.zeros(Nexp)\n",
    "array_Prob_Osc = np.zeros(Nexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over number of experiments to generate data and subsequent Chi2 values:\n",
    "for iexp in range( Nexp ) : \n",
    "\n",
    "    # Generate points:\n",
    "    xOsc = np.arange(NpointsOsc)+1\n",
    "    yOsc = mean + amp*np.cos(omega*xOsc + phase) + r.normal(0, sigmay, NpointsOsc)\n",
    "    syOsc = sigmay*np.ones_like(xOsc)\n",
    "\n",
    "    # Fit points:\n",
    "    def fit_function_Osc(x, mean, amp, omega, phase):\n",
    "        return mean + amp*np.cos(omega*x + phase)\n",
    "    \n",
    "    mfitOsc = LeastSquares( xOsc, yOsc, syOsc, fit_function_Osc)\n",
    "    mfitOsc = Minuit(mfitOsc, mean=mean, amp=amp, omega=omega, phase=phase)  \n",
    "    mfitOsc.migrad();                # Perform the actual fit\n",
    "\n",
    "    Chi2Osc = mfitOsc.fval           # Get the chi2 value\n",
    "    NvarOsc = 4                      # Number of variables (mean, amp, omega, phase)\n",
    "    NdofOsc = NpointsOsc - NvarOsc   # Number of degrees of freedom    \n",
    "    ProbOsc =  stats.chi2.sf(Chi2Osc, NdofOsc)   # The chi2 probability given N degrees of freedom, Ndof\n",
    "    \n",
    "    array_Chi2_Osc[iexp] = Chi2Osc\n",
    "    array_Prob_Osc[iexp] = ProbOsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figOsc, axOsc = plt.subplots(figsize=(16, 8))\n",
    "axOsc.errorbar(xOsc, yOsc, syOsc, fmt='ro', ecolor='k', elinewidth=1, capsize=2, capthick=1, label=\"Data\")\n",
    "xaxis = np.linspace(min(xOsc), max(xOsc), 1000)\n",
    "axOsc.plot(xaxis, fit_function_Osc(xaxis, *mfitOsc.values[:]), '-r', label=\"Fit\")\n",
    "first_legend = axOsc.legend(fontsize=18, loc=\"upper left\");\n",
    "\n",
    "chi2 = mfitOsc.fval                     # ChiSquare value\n",
    "Ndof = len(xLin[yLin > 0]) - mfitOsc.nfit     # Number of (non-empty) bins\n",
    "Prob = stats.chi2.sf(chi2, Ndof)     # ChiSquare probability given Ndof\n",
    "\n",
    "fit_info = (\n",
    "    f\"$\\\\chi^2$ / $N_\\\\mathrm{{dof}}$ = {chi2:.1f} / {Ndof}\\n\"\n",
    "    f\"Prob($\\\\chi^2$, $N_\\\\mathrm{{dof}}$) = {Prob:.3f}\\n\"\n",
    ")\n",
    "for p, v, e in zip(mfitOsc.parameters, mfitOsc.values[:], mfitOsc.errors[:]) :\n",
    "    Ndecimals = max(0,-np.int32(np.log10(e)-1-np.log10(2)))                                # Number of significant digits\n",
    "    fit_info+=(f\"{p} = ${v:{10}.{Ndecimals}{\"f\"}} \\\\pm {e:{10}.{Ndecimals}{\"f\"}}$\\n\")\n",
    "\n",
    "# Add result of fit on the plot in a separate legend\n",
    "fit_results, = plt.plot([],[],color='none',label=fit_info)\n",
    "second_legend = plt.legend(title=\"Result of fit:\", handles=[fit_results], fontsize=18, title_fontsize = 20, alignment = 'left', handlelength=0, handletextpad=0);\n",
    "axOsc.add_artist(first_legend);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save_plots) : \n",
    "    figOsc.savefig(\"Chi2Dist_OscillationFit.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and fit EXPONENTIAL binned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NpointsExp = 1000   # Put this number of points (exponentially distributed) in each histogram.\n",
    "NbinsExp = 17       # Decide on the number of bins (for a reason!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 3.14           # I'm just picking a random lifetime..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_Chi2_Exp = np.zeros(Nexp)\n",
    "array_Prob_Exp = np.zeros(Nexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define an exponential fit function, which includes a normalisation:\n",
    "def fit_function_Exp(x, tau, N) :\n",
    "    return N / tau * np.exp(- x / tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over number of experiments to generate data and subsequent Chi2 values:\n",
    "for iexp in range( Nexp ) : \n",
    "    \n",
    "    dataExp = r.exponential(tau, NpointsExp)\n",
    "\n",
    "    yExp, xExp_edges = np.histogram(dataExp, bins=NbinsExp, range=(0, NbinsExp))\n",
    "    xExp = (xExp_edges[1:] + xExp_edges[:-1])/2\n",
    "    syExp = np.sqrt(yExp)\n",
    "    \n",
    "    mfitExp = LeastSquares( xExp[yExp>0], yExp[yExp>0], syExp[yExp>0], fit_function_Exp)\n",
    "    mfitExp = Minuit(mfitExp, tau = tau, N=NpointsExp)  \n",
    "    mfitExp.migrad();  # perform the actual fit\n",
    "\n",
    "    Chi2Exp = mfitExp.fval\n",
    "    NvarExp = 2                                   # Number of variables (N and tau)\n",
    "    NdofExp = len(yExp[yExp > 0]) - NvarExp       # Number of degrees of freedom\n",
    "    ProbExp =  stats.chi2.sf(Chi2Exp, NdofExp)    # The chi2 probability given Ndof degrees of freedom\n",
    "    \n",
    "    array_Chi2_Exp[iexp] = Chi2Exp\n",
    "    array_Prob_Exp[iexp] = ProbExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figExp, axExp = plt.subplots(figsize=(16, 8))\n",
    "axExp.hist(dataExp, NbinsExp, range=(0, NbinsExp), histtype='step', label=\"Data\")\n",
    "x_axis = np.linspace(0, NbinsExp, 1000)\n",
    "axExp.plot(x_axis, fit_function_Exp(x_axis, *mfitExp.values[:]), '-r', label=\"Fit\") \n",
    "first_legend = axExp.legend(fontsize=18, loc=\"upper right\");\n",
    "\n",
    "chi2 = mfitExp.fval                           # ChiSquare value\n",
    "Ndof = len(xLin[yLin > 0]) - mfitExp.nfit     # Number of (non-empty) bins\n",
    "Prob = stats.chi2.sf(chi2, Ndof)              # ChiSquare probability given Ndof\n",
    "\n",
    "fit_info = (\n",
    "    f\"$\\\\chi^2$ / $N_\\\\mathrm{{dof}}$ = {chi2:.1f} / {Ndof}\\n\"\n",
    "    f\"Prob($\\\\chi^2$, $N_\\\\mathrm{{dof}}$) = {Prob:.3f}\\n\"\n",
    ")\n",
    "\n",
    "for p, v, e in zip(mfitExp.parameters, mfitExp.values[:], mfitExp.errors[:]) :\n",
    "    Ndecimals = max(0,-np.int32(np.log10(e)-1-np.log10(2)))                                # Number of significant digits\n",
    "    fit_info+=(f\"{p} = ${v:{10}.{Ndecimals}{\"f\"}} \\\\pm {e:{10}.{Ndecimals}{\"f\"}}$\\n\")\n",
    "\n",
    "# Add result of fit on the plot in a separate legend\n",
    "fit_results, = plt.plot([],[],color='none',label=fit_info)\n",
    "plt.legend(title=\"Result of fit:\", handles=[fit_results], fontsize=18, title_fontsize = 20, alignment = 'left', handlelength=0, handletextpad=0, loc=\"right\");\n",
    "axExp.add_artist(first_legend);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if (save_plots) : \n",
    "    figExp.savefig(\"Chi2Dist_ExponentialFit.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above histogram does not show us the uncertainty used in each bin, which the $\\chi^2$ needs for its calculation. We have discussed what error to use, and will surely be doing so more in the course, but below is code that gives a plot showing points and errors instead of a \"bare\" histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating points and errors:\n",
    "y, bin_edges = np.histogram(dataExp, bins=NbinsExp, range=(0, NbinsExp))\n",
    "x = 0.5*(bin_edges[:-1] + bin_edges[1:])\n",
    "sy = np.sqrt(y)                             # Note: Ask yourself (here on in question 4 below) where these errors come from?\n",
    "\n",
    "# Plotting the result of the above!\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "hist1 = ax.errorbar(x, y, sy, fmt='.', label='Exponential distribution')\n",
    "\n",
    "# Plot the function we fitted on top? That is a simple exercise for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considering repeated experiments/fits and resulting $\\chi^2$ distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there have been more than one experiment, then make another white canvas:\n",
    "if (Nexp > 1) :\n",
    "    \n",
    "    xaxis = np.linspace(0, 50, 1000)\n",
    "    yaxis = stats.chi2.pdf(xaxis, 15)   # This is the Chi2 distribution with 15 DOF.\n",
    "    \n",
    "    array_Chi2 = [array_Chi2_Lin, array_Chi2_Osc, array_Chi2_Exp]\n",
    "\n",
    "    fig2, ax2 = plt.subplots(ncols=3, figsize=(16, 6))\n",
    "    for i in range(3):\n",
    "        ax2[i].hist(array_Chi2[i], 50, range=(0, 50), histtype='step', density=True)    # Plot normalised!\n",
    "        ax2[i].plot(xaxis, yaxis)\n",
    "    \n",
    "        # Here, we \"just\" put in quick remarks (note the \"code\"-like way of defining format. Do you understand it?):\n",
    "        string  = f\"Entries {len(array_Chi2[i]):7d}\\n\"\n",
    "        string += f\"Mean {array_Chi2[i].mean():10.3f}\\n\"\n",
    "        string += f\"STD {array_Chi2[i].std(ddof=1):11.3f}\"\n",
    "        ax2[i].text(0.6, 0.95, string, family='monospace', transform=ax2[i].transAxes, fontsize=10, verticalalignment='top')\n",
    "        \n",
    "    if (save_plots) : \n",
    "        fig2.savefig(\"Chi2Dist_SeveralCases.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    " 1. Why have I chosen the three examples to have 17 points, 19 points and 17 bins?\n",
    "    Hint: What is the number of degrees of freedom in each of the three cases?\n",
    "\n",
    "**Example answer 1**:\n",
    "With this choice of number of points/bins, we made sure that Ndof of all three distributions is the same, namely 15, as the number of fit parameters are 2, 4, and 2, respectively. Therefore, the three $\\chi^2$ distributions are (statistically) identical, and follow the ChiSquare distribution for 15 degrees of freedom.\n",
    "\n",
    "---\n",
    "\n",
    " 2. In the example of the linear fit, what number of points lies outside +-1 sigma?\n",
    "    Is that a reasonable number?\n",
    "\n",
    "**Example answer 2**:\n",
    "4 out of 15 points (27% of all points). Assuming that uncertainties are Gaussian, 68% of points should like within $\\pm 1 \\sigma$. Therefore it is a very reasonable number (we have to consider that we have \"only\" 15 points).\n",
    "\n",
    "---\n",
    "\n",
    " 3. In the oscillatory case, try to drop the part were you set the initial parameters\n",
    "    or simply set them to zero, and see how well the fit goes, when it does not\n",
    "    have good starting values. How often does it get a good fit result?\n",
    "\n",
    "**Example answer 3**:\n",
    "Even in this very simple case with only four parameters, the fit has a hard time finding the minimum, if good input values are not given! We'll return to this point, but whenever a fit fails, you should start by looking at the input parameters. A good option is simply to draw the model on top of the data, to check that it is even remotely close. When it is... release the power of the fit!\n",
    "\n",
    "---\n",
    "\n",
    " 4. In the exponential fit, where do the uncertainties come from? And is the fit reasonable?\n",
    "\n",
    "**Example answer 4**:\n",
    "The uncertainties come from the assumption, that the number of events in each bin is Poisson distributed (i.e. uncertainties are $\\sqrt{N}$), and that the number of entries is high enough, that this can be approximated well with a Gaussian.\n",
    "This is in fact an approximation, as the bins in the tail do not really have enough statistics for this to hold true. However, these bins are few and in a non-essential place, so the fit should still behave well and give good results. But if the statistics was less and/or the tail longer, one could run into problems.\n",
    "    \n",
    "\n",
    "### Advanced questions:\n",
    " 5. Why does the last of the three Chi2 distributions not fit quite?\n",
    "    Try to change the number of generated points to 100 instead of 1000,\n",
    "    and/or change the lifetime to tau=2.1. Does this increase the mismatch\n",
    "    of the Chi2 distribution. Does that give you a hint why?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning points:\n",
    "\n",
    "This exercise simply gives more ChiSquare fitting illustrations, yet with the same number of degrees of freedom (Ndof) in the fit. From this exercise you should simply get the knowledge of how to run a ChiSquare fit in different situations/cases, calculate Ndof, and be able to extract the p-value."
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "appstat25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "main_language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
