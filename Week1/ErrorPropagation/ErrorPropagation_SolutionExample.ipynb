{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Propagation using Random Gaussian Numbers\n",
    "\n",
    "Example calculation of propagating uncertainties, both when adding and multiplying number, and also in the general case. The propagation can be done both analytically (using the error propagation formula) and also using simulation.\n",
    "\n",
    "The example is based on FIRST doing the error propagation **analytically**, and then verifying it by running a so-called Monte-Carlo (MC) program, which uses random numbers for propagating errors.\n",
    "\n",
    "## References:\n",
    "- Barlow: page 48-61\n",
    "- Bevington: page 36-48\n",
    "\n",
    "## Author(s), contact(s), and dates:\n",
    "- Author: Troels C. Petersen (NBI)\n",
    "- Email:  petersen@nbi.dk\n",
    "- Date:   22th of November 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "DO THE FOLLOWING ANALYTICAL EXERCISE FIRST!!!\n",
    "\n",
    "1. A class of students estimate by eye, that the length of the table in Auditorium A is $L = (3.5\\pm 0.4)$m, and that the width is $W = (0.8\\pm 0.2)$m.\n",
    "\n",
    "   Assuming that there is no correlation between these two measurements, calculate ANALYTICALLY what the Perimeter (P), area (A), and diagonal (D) length is including (propagated) uncertainties. Repeat the calculation, given that the correlation between length and width is $\\rho(L,W) = 0.5$ - not an unreasonable number, given that they are estimated by the same (uncertain) scale.\n",
    "   \n",
    "NOTE: This is a complete standard problem, that you will be asked to solve again and again in the course. For this reason, make sure that you understand how to do it, and become good at doing it reasonably fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1   =  3.5\n",
    "sig1  =  0.4\n",
    "mu2   =  0.8\n",
    "sig2  =  0.2\n",
    "rho12 =  0.5           # Correlation parameter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the correlation is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (-1.0 <= rho12 <= 1.0): \n",
    "    raise ValueError(f\"Correlation factor not in interval [-1,1], as it is {rho12:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on analytic solutions with SymPy:\n",
    "\n",
    "Python includes symbolic algebra in the package *SymPy*, which is both simple and powerful (and in Python). In addition, printing with Latex can also be included (see below), which (in combination) is very nice.\n",
    "\n",
    "Below is a SymPy and Latex example with the hope that it will wet your appetite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Latex\n",
    "\n",
    "def lprint(*args,**kwargs):\n",
    "    \"\"\"Pretty print arguments as LaTeX using IPython display system \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : tuple \n",
    "        What to print (in LaTeX math mode)\n",
    "    kwargs : dict \n",
    "        optional keywords to pass to `display` \n",
    "    \"\"\"\n",
    "    display(Latex('$$'+' '.join(args)+'$$'),**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myDiff(formula):\n",
    "    return sqrt((formula.diff(L) * dL)**2 + (formula.diff(W) * dW)**2)\n",
    "\n",
    "def myDiffWithCorr(formula, name = \"\", printNow = False):\n",
    "    dd = sqrt((formula.diff(L) * dL)**2 + (formula.diff(W) * dW)**2 + 2*(formula.diff(L)*formula.diff(W)*(sigCorr**2)))\n",
    "    if(printNow):\n",
    "        lprint(latex(Eq(symbols('sigma_'+name), dd)))\n",
    "    fd = lambdify((L,dL,W,dW,sigCorr),dd)\n",
    "    return dd, fd\n",
    "    \n",
    "def diff_and_print(formula, name = \"\"):\n",
    "    # Calculate uncertainty and print original relation/formula and the uncertainty\n",
    "    dd = myDiff(formula)\n",
    "    lprint(latex(Eq(symbols(name),formula)))\n",
    "    lprint(latex(Eq(symbols('sigma_'+name), dd)))\n",
    "    \n",
    "def lambdifyFormula(formula, *args, name = \"\"):\n",
    "    # Turn expression into numerical functions \n",
    "    f = lambdify((L,W),formula)\n",
    "    d = myDiff(formula)\n",
    "    fd = lambdify((L,dL,W,dW),d)\n",
    "    return f, fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SymPy: \n",
    "from sympy import * \n",
    "\n",
    "# Define variables:\n",
    "L,W,P,A,D = symbols(\"L, W, P, A, D\")\n",
    "dL,dW,dP,dA,dD = symbols(\"sigma_L, sigma_W, sigma_P, sigma_A, sigma_D\")\n",
    "\n",
    "# Define relations:\n",
    "# Perimeter:\n",
    "P = 2*L + 2*W\n",
    "# Area:\n",
    "A = L*W\n",
    "# Diagonal\n",
    "D = sqrt(L**2 + W**2)\n",
    "\n",
    "# Try writing a simple function to not repeat yourself! (See cell above)\n",
    "diff_and_print(P,\"P\")\n",
    "diff_and_print(A,\"A\")\n",
    "diff_and_print(D,\"D\")\n",
    "\n",
    "dP = myDiff(P)\n",
    "dA = myDiff(A)\n",
    "dD = myDiff(D)\n",
    "\n",
    "# Turn expressions into numerical functions \n",
    "fP, fdP = lambdifyFormula(P,\"P\")\n",
    "fA, fdA = lambdifyFormula(A,\"A\")\n",
    "fD, fdD = lambdifyFormula(D,\"D\")\n",
    "\n",
    "# Define values and their errors\n",
    "vL, vdL = mu1,sig1\n",
    "vW, vdW = mu2,sig2\n",
    "\n",
    "# Numerically evaluate expressions and print \n",
    "vP = fP(vL,vW)\n",
    "vdP = fdP(vL,vdL,vW,vdW)\n",
    "vA = fA(vL,vW)\n",
    "vdA = fdA(vL,vdL,vW,vdW)\n",
    "vD = fD(vL,vW)\n",
    "vdD = fdD(vL,vdL,vW,vdW)\n",
    "\n",
    "lprint(fr'P = ({vP:.1f} \\pm {vdP:.1f})\\,\\mathrm{{m}}')\n",
    "lprint(fr'A = ({vA:.1f} \\pm {vdA:.1f})\\,\\mathrm{{m}}')\n",
    "lprint(fr'D = ({vD:.1f} \\pm {vdD:.1f})\\,\\mathrm{{m}}')\n",
    "\n",
    "#Adding correlations (and also derivation, printing and lambdifying)\n",
    "sigCorr = symbols(\"sigma_LW\")\n",
    "rho = symbols(\"rho_LW\")\n",
    "\n",
    "dP, fdP = myDiffWithCorr(P, \"P\", True)\n",
    "dA, fdA = myDiffWithCorr(A, \"A\", True)\n",
    "dD, fdD = myDiffWithCorr(D, \"D\", True)\n",
    "\n",
    "sCorr = sqrt(rho*dL*dW)\n",
    "fSC = lambdify((rho,dL,dW),sCorr)\n",
    "\n",
    "vSigmaCorr = fSC(rho12,vdL,vdW)\n",
    "\n",
    "# Numerically evaluate expressions and print \n",
    "vdP = fdP(vL,vdL,vW,vdW,vSigmaCorr)\n",
    "vdA = fdA(vL,vdL,vW,vdW,vSigmaCorr)\n",
    "vdD = fdD(vL,vdL,vW,vdW,vSigmaCorr)\n",
    "\n",
    "lprint(fr'P = ({vP:.1f} \\pm {vdP:.1f})\\,\\mathrm{{m}}')\n",
    "lprint(fr'A = ({vA:.1f} \\pm {vdA:.1f})\\,\\mathrm{{m}}')\n",
    "lprint(fr'D = ({vD:.1f} \\pm {vdD:.1f})\\,\\mathrm{{m}}')\n",
    "\n",
    "# NOTE: Do the above analytical calculation before you continue below! Possibly use SymPy for the differentiations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                     # Matlab like syntax for linear algebra and functions\n",
    "import matplotlib.pyplot as plt                        # Plots and figures like you know them from Matlab\n",
    "from iminuit import Minuit                             # The actual fitting tool, better than scipy's\n",
    "import sys                                             # Modules to see files and folders in directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error propagation - Simulation\n",
    "\n",
    "Now we want to try to see, if we can solve the above error propagation problem using simulation. The method is relatively straight forward: You simply take \"realistic\" values of the input parameters x (here Length (x1) and Width (x2)), calculate the resulting value y (here Perimeter, Area, and Diagonal), and do this many times. The resulting distribution of y should be centered around the value y(x1,x2), and the standard deviation should reflect the uncertainty in y from the uncertainties in the input variables.\n",
    "\n",
    "This is a much more clumsy way of calculating the uncertainty, but comes with the advantage, that if the resulting uncertainty is not Gaussian, then one can actually see this (i.e. it avoids the assumptions used in the usual error propagation formula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we set the parameters of the program:\n",
    "N_exp = 10000           # Number of \"experiments\" (i.e. drawing from random distributions)\n",
    "save_plots = False\n",
    "r = np.random\n",
    "r.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing random numbers with a correlation:\n",
    "\n",
    "Below we have used the build in Numpy method for producing two random Gaussian numbers with a correation between them.\n",
    "\n",
    "You can also do this \"yourself\", see Barlow page 42-44 for method. Essentially, the method is to generate uncorrelated Gaussian numbers, and then \"rotating\" these, where the amount of rotation controls the correlation wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce random numbers with (a possible) correlation:\n",
    "cov = np.array([[sig1**2, rho12*sig1*sig2],\n",
    "                [rho12*sig1*sig2, sig2**2]])\n",
    "x12_all = np.random.multivariate_normal([mu1, mu2], cov, size=N_exp)\n",
    "\n",
    "# Now we use the input variables (x1 and x2) to calculate y for the three different cases:\n",
    "y_all_P = 2*x12_all[:,0] + 2*x12_all[:,1]               # Perimeter (P)\n",
    "y_all_A = x12_all[:,0] * x12_all[:,1]                   # Area (A)\n",
    "y_all_D = np.sqrt(x12_all[:,0]**2 + x12_all[:,1]**2)    # Diagonal (D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Plot both input distribution and resulting 2D-histogram on screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "counts, xedges, yedges, im = ax.hist2d(x12_all[:,0], x12_all[:,1], bins=[120, 80], range=[[0.0, 6.0], [-1.0, 3.0]], cmin=1)\n",
    "ax.plot([0.0, 6.0], [0.0, 0.0], \"--k\")    # This is a dashed black line from [x1, x2], [y1, y2] with dashed line\n",
    "fig.colorbar(im)\n",
    "ax.set(title='Histogram of lengths (x) and widths (y)', xlabel='x', ylabel='y')\n",
    "\n",
    "plot_info = [f\"Entries = {len(x12_all)}\",\n",
    "             f\"Mean x = {x12_all[:,0].mean():5.3f}\",\n",
    "             f\"Mean y = {x12_all[:,1].mean():5.3f}\",\n",
    "             f\"Std x = {x12_all[:,0].std(ddof=1):5.3f}\",\n",
    "             f\"Std y = {x12_all[:,1].std(ddof=1):5.3f}\"]\n",
    "ax.text(0.1, 0.8, \"\\n\".join(plot_info), family='monospace', fontsize=15, transform = ax.transAxes);\n",
    "\n",
    "fig.tight_layout()\n",
    "fig\n",
    "\n",
    "if save_plots :\n",
    "    fig.savefig(\"Dist_2Dgauss.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the resulting distribution:\n",
    "\n",
    "Now we look at the `y_all` distribution, which should be Gaussian if the error propagation formula holds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, N, mu, sigma):\n",
    "    return N / (sigma*np.sqrt(2*np.pi)) * np.exp(-0.5* (x-mu)**2/sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perimeter:\n",
    "# ----------\n",
    "# Always make sure, that you control the binning and range!\n",
    "nbins = 100\n",
    "xmin, xmax = 5.0, 15.0\n",
    "binwidth = (xmax-xmin)/nbins\n",
    "print(f\"  Mean = {y_all_P.mean():5.3f},    Std = {y_all_P.std(ddof=1):5.3f}\")\n",
    "\n",
    "figP, axP = plt.subplots(figsize=(16, 6));\n",
    "countsP, bin_edgesP, _ = axP.hist(y_all_P, nbins, range=(xmin, xmax), histtype='step', linewidth=2)\n",
    "bin_centersP = (bin_edgesP[1:] + bin_edgesP[:-1])/2\n",
    "s_countsP = np.sqrt(countsP)\n",
    "\n",
    "# Draw Gaussian from analytical calculation on top:\n",
    "xaxis = np.linspace(xmin, xmax, 1000)\n",
    "yaxis = binwidth * gaussian(xaxis, N_exp, vP, vdP)\n",
    "axP.plot(xaxis, yaxis, linewidth=2)\n",
    "\n",
    "figP.tight_layout()\n",
    "figP\n",
    "\n",
    "if save_plots:\n",
    "    fig2.savefig(\"Dist_ErrorProp_Perimeter.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area:\n",
    "# -----\n",
    "# Always make sure, that you control the binning and range!\n",
    "nbins = 100\n",
    "xmin, xmax = 0.0, 10.0\n",
    "binwidth = (xmax-xmin)/nbins\n",
    "print(f\"  Mean = {y_all_A.mean():5.3f},    Std = {y_all_A.std(ddof=1):5.3f}\")\n",
    "\n",
    "figA, axA = plt.subplots(figsize=(16, 6));\n",
    "countsA, bin_edgesA, _ = axA.hist(y_all_A, nbins, range=(xmin, xmax), histtype='step', linewidth=2)\n",
    "bin_centersA = (bin_edgesA[1:] + bin_edgesA[:-1])/2\n",
    "s_countsA = np.sqrt(countsA)\n",
    "\n",
    "# Draw Gaussian from analytical calculation on top:\n",
    "xaxis = np.linspace(xmin, xmax, 1000)\n",
    "yaxis = binwidth * gaussian(xaxis, N_exp, vA, vdA)\n",
    "axA.plot(xaxis, yaxis, linewidth=2)\n",
    "\n",
    "figP.tight_layout()\n",
    "figP\n",
    "\n",
    "if save_plots:\n",
    "    fig2.savefig(\"Dist_ErrorProp_Area.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diagonal:\n",
    "# ---------\n",
    "# Always make sure, that you control the binning and range!\n",
    "nbins = 100\n",
    "xmin, xmax = 0.0, 5.0\n",
    "binwidth = (xmax-xmin)/nbins\n",
    "print(f\"  Mean = {y_all_D.mean():5.3f},    Std = {y_all_D.std(ddof=1):5.3f}\")\n",
    "\n",
    "figD, axD = plt.subplots(figsize=(16, 6));\n",
    "countsD, bin_edgesD, _ = axD.hist(y_all_D, nbins, range=(xmin, xmax), histtype='step', linewidth=2)\n",
    "bin_centersD = (bin_edgesD[1:] + bin_edgesD[:-1])/2\n",
    "s_countsD = np.sqrt(countsD)\n",
    "\n",
    "# Draw Gaussian from analytical calculation on top:\n",
    "xaxis = np.linspace(xmin, xmax, 1000)\n",
    "yaxis = binwidth * gaussian(xaxis, N_exp, vD, vdD)\n",
    "axD.plot(xaxis, yaxis, linewidth=2)\n",
    "\n",
    "figP.tight_layout()\n",
    "figP\n",
    "\n",
    "if save_plots:\n",
    "    fig2.savefig(\"Dist_ErrorProp_Diagonal.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Questions:\n",
    "\n",
    "0. First solve the problem of obtaining the Perimeter, Area & Diagonal with uncertainty ANALYTICALLY.\n",
    "\n",
    "**Example answer 0**: \n",
    "\n",
    "See cell 4. No need to differentiate by hand, SymPy can do it easily for you.\n",
    "\n",
    "---\n",
    "\n",
    "1. Now look at the program, and assure yourself that you understand what is going on. Put in the correct expression for y in terms of x1=L and x2=W in order to calculate the perimeter, area, and diagonal length, and run the program. Does the output correspond well with the results you expected from your analytical calculations to begin with?\n",
    "\n",
    "**Example answer 1**:\n",
    "Yes, both the mean value and the uncertainty are in a very good agreement to the results from analytical calculations. In the area calculation, there is a slight discrepancy, simply because multiplying two Gaussians does not give (exactly) a Gaussian... only when adding! \n",
    "Also, one little thing to note is, that the width can actually come out negatively in rare cases (i.e. beyond 4 sigma low). When producing a simulation of cases, one should of course be aware of such things!\n",
    "\n",
    "---\n",
    "\n",
    "2. Imagine that you wanted to know the central value and uncertainty of y1 and y2, given the\n",
    "   same above PDFs for `x1`=$L$ and `x2`=$W$:\n",
    "   \n",
    "     `y1 = log(square(x1*tan(x2))+sqrt((x1-x2)/(cos(x2)+1.0+x1)))`\n",
    "     \n",
    "     `y2 = 1.1+sin(20*x1)`\n",
    "\n",
    "   Get the central value of y, and see if you can quickly differentiate this with\n",
    "   respect to `x1` and `x2`, and thus predict what uncertainty to expect for y using\n",
    "   the error propagation formula. It is (for once) OK to give up on the first expression :-)\n",
    "   Next, try to estimate the central value and uncertainty using random numbers\n",
    "   like above - do you trust this result more? And are the distributions Gaussian?\n",
    "\n",
    "**Example answer 2**:\n",
    "The first expression \"y1\" looks horrible, and it is! This is an obvious case where simulation is probably a better way forward, and at least a good cross check.\n",
    "The second expression \"y2\" is simple, but made to make the error propagation formula break down! The function varies wildly, and as a result, the error propagation formula assumption is broken (badly). The resulting error distribution is also very far from Gaussian, as can be seen below.\n",
    "\n",
    "For code solution example, see the code cell below.\n",
    "\n",
    "\n",
    "### Advanced questions:\n",
    "\n",
    "3. Try to generate `x1` and `x2` with non-linear correlation, which yields zero linear correlation,\n",
    "   and see that despite not having any linear correlation, the result on perimeter, area, and diagonal\n",
    "   length is still affected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1,y2,x1,x2 = symbols('y_1,y_2,x_1,x_2')\n",
    "dy1,dy2,dx1,dx2 = symbols('sigma_y_1,sigma_y_2,sigma_x_1,sigma_x_2')\n",
    "\n",
    "y1 = log(sqrt(x1+tan(x2)))+sqrt((x1-x2))/(cos(x2)+1+x1)\n",
    "lprint(latex(Eq(symbols('y_1'),y1)))\n",
    "\n",
    "y2 = 1.1 + sin(20*x1)\n",
    "lprint(latex(Eq(symbols('y_2'),y2)))\n",
    "\n",
    "dy1 = sqrt((y1.diff(x1) * dx1)**2 + (y1.diff(x2) * dx2)**2)\n",
    "lprint(latex(Eq(symbols('sigma_y_1'),dy1)))\n",
    "\n",
    "dy2 = sqrt((y2.diff(x1) * dx1)**2 + (y2.diff(x2) * dx2)**2)\n",
    "lprint(latex(Eq(symbols('sigma_y_2'),dy2)))\n",
    "\n",
    "fy1 = lambdify((x1,x2),y1)\n",
    "fy2 = lambdify((x1,x2),y2)\n",
    "\n",
    "fdy1 = lambdify((x1,dx1,x2,dx2),dy1)\n",
    "fdy2 = lambdify((x1,dx1,x2,dx2),dy2)\n",
    "\n",
    "vx1,vdx1 = mu1,sig1\n",
    "vx2,vdx2 = mu2,sig2\n",
    "\n",
    "vy1 = fy1(vx1,vx2)\n",
    "vdy1 = fdy1(vx1,vdx1,vx2,vdx2)\n",
    "vy2 = fy2(vx1,vx2)\n",
    "vdy2 = fdy2(vx1,vdx1,vx2,vdx2)\n",
    "\n",
    "lprint(fr'y1 = ({vy1:.1f} \\pm {vdy1:.1f})\\,\\mathrm{{m}}')\n",
    "lprint(fr'y2 = ({vy2:.1f} \\pm {vdy2:.1f})\\,\\mathrm{{m}}') \n",
    "\n",
    "# Define the parameters needed for the transformation:\n",
    "theta = 0.5 * np.arctan( 2.0 * rho12 * sig1 * sig2 / ( np.square(sig1) - np.square(sig2) ) )\n",
    "sigu = np.sqrt( np.abs( (((sig1*np.cos(theta))**2) - (sig2*np.sin(theta))**2 ) / ( (np.cos(theta))**2 - np.sin(theta)**2) ) )\n",
    "sigv = np.sqrt( np.abs( (((sig2*np.cos(theta))**2) - (sig1*np.sin(theta))**2 ) / ( (np.cos(theta))**2 - np.sin(theta)**2) ) )\n",
    "\n",
    "\n",
    "u = r.normal(0.0, sigu, N_exp)\n",
    "v = r.normal(0.0, sigv, N_exp)\n",
    "x1_all = mu1 + np.cos(theta)*u - np.sin(theta)*v\n",
    "x2_all = mu2 + np.sin(theta)*u + np.cos(theta)*v\n",
    "x12_all = np.array([x1_all, x2_all])\n",
    "\n",
    "y_all = 1.1 + np.sin(20*x1_all)\n",
    "\n",
    "xmin, xmax = 0.0, 3.0\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 6));\n",
    "counts, bin_edges, _ = ax3.hist(y_all, 100, range=(xmin, xmax), histtype='step');\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "s_counts = np.sqrt(counts)\n",
    "\n",
    "print(f\"  Mean = {y_all.mean():5.3f},    RMSE = {y_all.std(ddof=1):5.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning points:\n",
    "\n",
    "Through this exercise, you should understand, that uncertainties (errors in slang) propagation can be in **two ways**:\n",
    "1. **Analytically**, propergating the uncertainties by differentiating the formula/relation in question.\n",
    "2. **Numerically** (i.e. simulation), by using random numbers reflecting the uncertainties on the input parameters, and calculating the final resulting number many times from these, noting the variation.\n",
    "\n",
    "You should be capable of **using both methods** effortlessly and with confidence.\n",
    "\n",
    "The analytical method is simple and transparent, but not always robust, as it requires that the error propagation formula holds. The numerical method is simple and robust, but not transparent. Using both methods is a great way of cross checking.\n",
    "\n",
    "Finally, you should understand, that error propagation plays an essential role in science, and that it is also used in planning of experiments (to minimise the error on the final quantity of interest)."
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "appstat25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
